# 第一章 分布式架构
## 集中式到分布式
+ 分布式: 一个硬件或者软件分布在不同的网络计算机上，彼此间仅仅通过消息进行通信和协调的系统
+ CAP定律: 分布式系统不可能全部满足，最多只能满足其中的两点
    - 一致性(Consistency): 多个系统之间的数据保持一致
    - 可用性(availability): 每个操作请求都能在有限时间内返回结果
    - 分区容错性(partition tolerance): 一部分机器故障，但是分布式系统对外仍为正常
+ BASE理论:
    - 基本可用(basically available): 系统出现故障时允许损失部分的可用性(响应时间损失、功能损失)
    - 软状态(soft state): 允许系统中的数据存在中间状态，也就是数据在不同机器上可以存在一定的延时
    - 最终一致性(eventually consistent):所有的数据经过一段时间的同步，最终数据会保持一致
        - 因果一致性
        - 读已之一致性
        - 会话一致性
        - 单调读一致性
        - 单调写一致性
# 第二章 一致性协议
分布式系统中一个机器无法知道其他机器的事务提交情况，需要引入Coordinator和Participant来决定是否把事务真正的提交
## 2PC (two phase commit)
+ 阶段一: 提交事务请求
    - 事务询问： 协调者向所有参与者发送事务内容，询问是否可以执行事务提交操作，并等待参与者的响应
    - 执行事务: 各参与者执行事务操作，并将Undo和Redo操作记录到事务中
    - 参与者反馈事务询问的响应: 
+ 阶段二: 执行事务提交
    - 发送提交请求: 向所有参与者节点发出Commit请求
    - 事务提交:参与者接收到commit请求后，会正式执行事务提交操作，并在提交完成后释放整个事务执行期间所占用的事务资源
    - 反馈事务提交结果: 参与者在完成事务提交后，想协调者发送ack确认消息
    - 完成事务:协调者接收到所有参与者反馈的ack确认消息，完成事务
+ 优点: 简单   
+ 存在的问题: 同步阻塞、单点问题、脑裂、太过保守    
    - 同步阻塞: 二阶段执行过程中，所有的参与者都处于阻塞的状态，已完成的参与者需要等待其他参与者的提交完成
    - 单点问题: 协调者出现问题导致参与者尚未完成的都会出现问题
    - 数据不一致性: 因为网络问题Commit部分机器没有收到消息导致数据不一致
    - 太过保守: 任意一个节点出错，整个分布式系统都会出错
## 3PC
+ 阶段一:CanCommit
    - 事务询问
    - 各参与者反馈是否可以提交事务
+ 阶段二: PreCommit(正常执行事务提交、中断事务)
    - 发送预提交请求
    - 事务预提交
    - 各参与者想协调者反馈事务执行的响应
    - 中断事务: 发送中断请求，参与者收到abort指令或者等待指令的时间内超时直接中断事务
+ 阶段三
    - 发送提交请求
    - 事务提交
    - 反馈事务完成结果
    - 完成事务
    - 中断事务: 发送中断请求，参与者收到abort指令或者等待指令的时间内超时直接中断事务
+ 优点: 相对于2PC来说，降低了参与者的阻塞范围，并且能够在出现单点故障之后继续保持一致性  
存在的问题:在preCommit阶段因为网络问题还是可能导致数据的不一致性

# 第三章 Paxos的工程实践
## Chubby
是一个分布式锁服务，Chubby



# Zookeeper基础
+ 协调：多个节点完成一个动作
+ 数据模型: 分层结构，树形结构中的每个节点叫做Znode,每个Znode都有数据(byte[]类型)，也可以有节点
    - 节点路径: 斜线分割: /Zoo/Duck
    - 没有相对路径
+ 通过数据结构stat来存储数据的变化，acl的变化和时间戳
+ 数据发生变化时，版本号会发生变化
+ 可以对Znode中的数据进行读写操作


## Zookeeper的应用场景
+ 数据发布/订阅(数据中心)
    - 发布者将数据发布到zk的一个或者一系列的节点上，订阅者进行数据订阅，当数据发生变化的时候，可以及时得到数据的变化通知
+ 负载均衡
    - 本质是利用zookeeper的配置管理功能，涉及到的步骤:
    - 1. 服务提供者把自己的域名ip端口注册到zk上
    - 2. 服务消费者通过域名从zk中获取到对应的ip及端口，这个ip端口有多个，只获取其中一个
    - 3. 当服务提供者宕机了，对应的域名与ip的对应就会减少一个映射
    - 4. 阿里的dubbo服务框架就是基于zk来实现服务路由和负载
+ 命名服务(类似jndi)
+ 分布式协调/通知
    - 通过watcher的通知机制实现
    - 分布式锁
    - 分布式事务
+ 集群管理
    - 当前机器中的机器数量
    - 集群中机器的运行状态
    - 集群中节点的上下线操作
    - 集群节点的统一配置
+ master选举
    - 临时节点
    - 顺序节点
+ 分布式锁
    - 排他锁
    - 共享锁
+ 分布式队列
    - FIFO
+ 集群角色
     - leader: 为客户端提供读和写的操作
     - follower: 提供读服务
     - observer: 提供读服务，不参与选举，一般是增强集群的读请求并发能力
+ 会话
    - zk的客户端和服务端之间的连接
    - 通过心跳检测保持客户端连接的存活
    - 接收来自服务端的watch事件通知
    - 可以设置超时时间
+ 版本
    - Version: 当前zNode的版本
    - Cversion: 当前zNode的子节点版本
    - Aversion: 当前zNode的ACL(访问控制)版本
+ watcher
    - 作用域zNode节点上
    - 多种事件通知: 数据更新、子节点状态
+ ACL(access control lists)
    - 类似于linux的权限控制
    - create: 创建子节点权限
    - read: 获取节点数据和子节点列表的权限
    - write: 更新节点数据的权限
    - delete: 删除子节点的权限
    - admin: 设置节点acl的权限

## zk的单机模式
### zkCli.cmd
+ 不带任何参数连接到localhost:2181 
+ zkCli.cmd -server localhost:2181

### ls
- ls path [watch]n
    - path表示指定数据节点的节点路径
    - 列出指定节点下的所有子节点
    - 只能查看第一级的所有子节点
    - 刚安装时 `ls / `下只有默认的zookeeper保留节点
    - watch表示监听path的子节点的变化
### create
- create [-s] [-e] path data acl
    - -s或者-e表示创建的是顺序或者临时节点，不加默认创建的是持久节点
    - path为节点的全路径，没有相对节点的表示方式
    - data为当前节点内存储的数据
    - acl用来进行权限控制，缺省情况不做任何权限控制
### get
- get path [watch]
    - 获取指定的数据内容和属性信息
    - Path表示指定数据节点的节点路径
### set
- set path data [version]
    - 更新指定节点的内容数据
    - version为指定被更新的数据版本，一般不指定，如果数据版本已经更新，则指定旧版本时会报错
### delete
- delete path [version]
    - 删除指定节点，path表示被删除的节点
    - version作为乐观锁控制
### Znode
+ 数据节点(Znode)
    - 不是机器的意思
    - zk树形结构中的数据节点，用于存储数据
    - 持久节点: 一旦创建，除非主动调用删除操作，否则一直存储在zk上
    - 临时节点: 与客户端的分享绑定，一旦客户端会话失效，这个客户端所有的创建节点都会被移除
    - SEQUENTIAL Znode: 创建节点时，如果设置属性SEQUENTIAL,则会自动在节点名后追加一个整型数字
+ 临时节点: 关闭会话时消失，创建的时候加上-e
+ watch
    - zk中引入watcher机制来实现发布订阅功能，能够让多个订阅者同时监听某一个主题对象
    - watcher设置后一旦触发一次就会失效，如果需要一直监听，就需要注册